!pip install numpy tensorflow nltk scikit-learn
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import json
import random
data = {
    "intents": [
        {"tag": "greeting",
         "patterns": ["Hi", "Hello", "Hey"],
         "responses": ["Hello!", "Hi there!"]
        },
        {"tag": "depression",
         "patterns": ["I feel sad", "I am depressed"],
         "responses": ["I'm sorry to hear that. Can you tell me more about what's been going on?", "It sounds like you're going through a tough time."]
        },
        {"tag": "suicidal_thoughts",
         "patterns": ["I want to end my life", "I am having suicidal thoughts"],
         "responses": ["I'm really sorry you're feeling this way, but I'm not equipped to help. Please contact a mental health professional or a crisis hotline immediately."]
        }
    ]
}

# Save data to a JSON file
with open("data.json", "w") as file:
    json.dump(data, file)
nltk.download('punkt')
nltk.download('stopwords')

def preprocess_data(data):
    le = LabelEncoder()
    patterns = []
    tags = []
    responses = {}
    
    for intent in data["intents"]:
        for pattern in intent["patterns"]:
            tokens = word_tokenize(pattern.lower())
            patterns.append(tokens)
            tags.append(intent["tag"])
        
        responses[intent["tag"]] = intent["responses"]
    
    return patterns, tags, responses

patterns, tags, responses = preprocess_data(data)
# Create a tokenizer and fit on the patterns
tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token="<OOV>")
tokenizer.fit_on_texts([' '.join(pattern) for pattern in patterns])
word_index = tokenizer.word_index

# Convert patterns to sequences
sequences = tokenizer.texts_to_sequences([' '.join(pattern) for pattern in patterns])

# Pad the sequences
padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')

# Encode the labels
le = LabelEncoder()
labels = le.fit_transform(tags)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2)

# Define the model
model = models.Sequential([
    layers.Embedding(input_dim=len(word_index) + 1, output_dim=16, input_length=padded_sequences.shape[1]),
    layers.GlobalAveragePooling1D(),
    layers.Dense(16, activation='relu'),
    layers.Dense(len(set(tags)), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))
def predict_intent(text):
    tokens = word_tokenize(text.lower())
    sequence = tokenizer.texts_to_sequences([' '.join(tokens)])
    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=padded_sequences.shape[1], padding='post')
    prediction = model.predict(padded_sequence)
    tag = le.inverse_transform([np.argmax(prediction)])
    return tag[0]

def get_response(intent):
    return random.choice(responses[intent])

def chatbot_response(text):
    intent = predict_intent(text)
    response = get_response(intent)
    return response
import logging

logging.basicConfig(filename='chatbot.log', level=logging.INFO)

def log_interaction(user_input, intent):
    logging.info(f"User Input: {user_input} | Predicted Intent: {intent}")

def chatbot_response(text):
    intent = predict_intent(text)
    response = get_response(intent)
    log_interaction(text, intent)
    return response
while True:
    user_input = input("You: ")
    if user_input.lower() in ["exit", "quit"]:
        break
    response = chatbot_response(user_input)
    print(f"Bot: {response}")
